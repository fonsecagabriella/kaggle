{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9192f17d",
   "metadata": {},
   "source": [
    "# Training models\n",
    "\n",
    "In this file we will take a methodical approach to run tests with different types of models, applying search spaces with HyOpt and recording the experiments in MLOps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b377b5a",
   "metadata": {},
   "source": [
    "## 1.0 Basic imports and setup\n",
    "\n",
    "- Start by running `mlflow` locally, run in the terminal:\n",
    "\n",
    "`mlflow ui --backend-store-uri file:./mlruns --port 5001`\n",
    "\n",
    "- Make sure you have the environment `ml_kaggle` activated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c69fdc97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start by importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import joblib\n",
    "import tempfile\n",
    "import json\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor # might import others as needed\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "\n",
    "from hyperopt import fmin, tpe, hp, Trials, STATUS_OK\n",
    "\n",
    "# local utils\n",
    "import sys\n",
    "sys.path.append('.')\n",
    "\n",
    "from src.utils import predict_and_create_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc89df79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to MLflow at: http://localhost:5001\n",
      "Tracking: http://localhost:5001\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' with mlflow.start_run(run_name=\"smoke-test\"):\\n    mlflow.log_param(\"ok\", True)\\n    mlflow.log_metric(\"ping\", 1.0)\\nprint(\"Logged a test run.\") '"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preparing for MLflow\n",
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient\n",
    "import mlflow.sklearn\n",
    "\n",
    "# -------------------------------\n",
    "# SETTINGS\n",
    "# -------------------------------\n",
    "EXPERIMENT_NAME = \"10_predicting_road_accident_risk\"\n",
    "SEED = 1\n",
    "RMSE_THRESHOLD = 0.057          # acceptable RMSE based on dummy model\n",
    "MAX_EVALS = 25                 # number of hyperopt trials\n",
    "N_JOBS = -1                    # RF parallelism\n",
    "\n",
    "# ---- Tracking URI from your .env ----\n",
    "port = os.getenv(\"MLFLOW_PORT\", \"5001\")\n",
    "\n",
    "# If notebook runs on HOST use localhost; if inside another container use service name 'mlflow'\n",
    "candidates = [f\"http://localhost:{port}\", f\"http://mlflow:{port}\"]\n",
    "\n",
    "last_err = None\n",
    "connected_uri = None\n",
    "for uri in candidates:\n",
    "    try:\n",
    "        mlflow.set_tracking_uri(uri)\n",
    "        client = MlflowClient()\n",
    "\n",
    "        # Health check compatible across MLflow versions\n",
    "        if hasattr(client, \"search_experiments\"):\n",
    "            _ = client.search_experiments(max_results=1)\n",
    "        elif hasattr(client, \"list_experiments\"):\n",
    "            _ = client.list_experiments()  # older MLflow\n",
    "        else:\n",
    "            # Fallback: try fetching the Default experiment (id \"0\")\n",
    "            _ = client.get_experiment_by_name(\"Default\") or client.get_experiment(\"0\")\n",
    "\n",
    "        connected_uri = uri\n",
    "        break\n",
    "    except Exception as e:\n",
    "        last_err = e\n",
    "\n",
    "if not connected_uri:\n",
    "    raise RuntimeError(f\"Could not reach MLflow. Last error: {last_err}\")\n",
    "\n",
    "print(\"Connected to MLflow at:\", connected_uri)\n",
    "\n",
    "# ---- Create/select your experiment ----\n",
    "mlflow.set_experiment(EXPERIMENT_NAME)\n",
    "print(\"Tracking:\", mlflow.get_tracking_uri())\n",
    "\n",
    "\n",
    "# Smoke test\n",
    "\"\"\" with mlflow.start_run(run_name=\"smoke-test\"):\n",
    "    mlflow.log_param(\"ok\", True)\n",
    "    mlflow.log_metric(\"ping\", 1.0)\n",
    "print(\"Logged a test run.\") \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b45a95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "train_data = pd.read_csv('data/train_split.csv')\n",
    "test_data = pd.read_csv('data/test_split.csv')\n",
    "\n",
    "y_train = train_data['accident_risk'].values\n",
    "y_test = test_data['accident_risk'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83f6c87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the features we will use\n",
    "num_features = ['curvature']\n",
    "cat_features = ['speed_limit', 'lighting', 'num_reported_accidents', 'weather']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cdb1616",
   "metadata": {},
   "source": [
    "## 2.0 Functions to train the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5db01f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(X, y, cat_features, num_features, model_name, model_config):\n",
    "    # Separate column types\n",
    "    # cat_features = ['speed_limit', 'lighting', 'num_reported_accidents', 'weather']\n",
    "    # num_features = [\"curvature\"]\n",
    "\n",
    "    # 1. Split the data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X[cat_features+num_features], y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # 2. Define transformers\n",
    "    # numeric_transformer = StandardScaler()   # optional for numeric stability\n",
    "\n",
    "    categorical_transformer = OneHotEncoder(\n",
    "        drop=\"first\",           # drop one dummy per category â†’ avoids multicollinearity\n",
    "        handle_unknown=\"ignore\" # handle unseen categories gracefully\n",
    "    )\n",
    "\n",
    "    # 3. Combine into a ColumnTransformer\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"num\", \"passthrough\", num_features),\n",
    "            (\"cat\", categorical_transformer, cat_cat_featurescols)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # 4. Build the pipeline\n",
    "    model = Pipeline(steps=[\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (model_name, model_config)\n",
    "    ])\n",
    "\n",
    "    # 5. Fit the model\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a826f6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_preprocessor(cat_cols, num_cols):\n",
    "    ohe = OneHotEncoder(drop=\"first\", handle_unknown=\"ignore\", sparse_output=True)\n",
    "    preproc = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"num\", \"passthrough\", num_cols),\n",
    "            (\"cat\", ohe, cat_cols),\n",
    "        ],\n",
    "        remainder=\"drop\",\n",
    "        sparse_threshold=1.0,   # keep sparse when possible\n",
    "    )\n",
    "    return preproc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60537995",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import hp\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "\n",
    "MODEL_REGISTRY = {\n",
    "    \"linreg\": {\n",
    "        \"factory\": lambda p: LinearRegression(),  # no hyperparams\n",
    "        \"space\": {}, \n",
    "        \"cast\": lambda p: p\n",
    "    },\n",
    "    \"ridge\": {\n",
    "        \"factory\": lambda p: Ridge(alpha=p[\"alpha\"], random_state=SEED),\n",
    "        \"space\": {\n",
    "            \"alpha\": hp.loguniform(\"alpha\", np.log(1e-4), np.log(1e3)),\n",
    "        },\n",
    "        \"cast\": lambda p: p,\n",
    "    },\n",
    "    \"lasso\": {\n",
    "        \"factory\": lambda p: Lasso(alpha=p[\"alpha\"], random_state=SEED, max_iter=20000),\n",
    "        \"space\": {\n",
    "            \"alpha\": hp.loguniform(\"alpha\", np.log(1e-4), np.log(1e1)),\n",
    "        },\n",
    "        \"cast\": lambda p: p,\n",
    "    },\n",
    "    \"elasticnet\": {\n",
    "        \"factory\": lambda p: ElasticNet(alpha=p[\"alpha\"], l1_ratio=p[\"l1_ratio\"], random_state=SEED, max_iter=20000),\n",
    "        \"space\": {\n",
    "            \"alpha\": hp.loguniform(\"alpha\", np.log(1e-4), np.log(1e1)),\n",
    "            \"l1_ratio\": hp.uniform(\"l1_ratio\", 0.0, 1.0),\n",
    "        },\n",
    "        \"cast\": lambda p: p,\n",
    "    },\n",
    "    \"rf\": {\n",
    "        \"factory\": lambda p: RandomForestRegressor(\n",
    "            n_estimators=p[\"n_estimators\"],\n",
    "            max_depth=p[\"max_depth\"],\n",
    "            min_samples_split=p[\"min_samples_split\"],\n",
    "            min_samples_leaf=p[\"min_samples_leaf\"],\n",
    "            max_features=p[\"max_features\"],\n",
    "            random_state=SEED,\n",
    "            n_jobs=-1,\n",
    "        ),\n",
    "        \"space\": {\n",
    "            \"n_estimators\": hp.quniform(\"n_estimators\", 100, 600, 1),\n",
    "            \"max_depth\": hp.pchoice(\"max_depth\", [(0.25, None), (0.75, hp.quniform(\"md_int\", 4, 40, 1))]),\n",
    "            \"min_samples_split\": hp.quniform(\"min_samples_split\", 2, 20, 1),\n",
    "            \"min_samples_leaf\": hp.quniform(\"min_samples_leaf\", 1, 20, 1),\n",
    "            \"max_features\": hp.choice(\"max_features\", [\"sqrt\", \"log2\", hp.uniform(\"max_feat_frac\", 0.3, 1.0)]),\n",
    "        },\n",
    "        \"cast\": lambda p: {\n",
    "            **p,\n",
    "            \"n_estimators\": int(p[\"n_estimators\"]),\n",
    "            \"max_depth\": None if p[\"max_depth\"] is None else int(p[\"max_depth\"]),\n",
    "            \"min_samples_split\": int(p[\"min_samples_split\"]),\n",
    "            \"min_samples_leaf\": int(p[\"min_samples_leaf\"]),\n",
    "            # max_features may be str or float â€“ leave as is\n",
    "        },\n",
    "    },\n",
    "    \"gbr\": {\n",
    "        \"factory\": lambda p: GradientBoostingRegressor(\n",
    "            n_estimators=p[\"n_estimators\"],\n",
    "            learning_rate=p[\"learning_rate\"],\n",
    "            max_depth=p[\"max_depth\"],\n",
    "            subsample=p[\"subsample\"],\n",
    "            min_samples_split=p[\"min_samples_split\"],\n",
    "            min_samples_leaf=p[\"min_samples_leaf\"],\n",
    "            random_state=SEED,\n",
    "        ),\n",
    "        \"space\": {\n",
    "            \"n_estimators\": hp.quniform(\"n_estimators\", 50, 500, 1),\n",
    "            \"learning_rate\": hp.loguniform(\"learning_rate\", np.log(1e-3), np.log(0.5)),\n",
    "            \"max_depth\": hp.quniform(\"max_depth\", 2, 8, 1),\n",
    "            \"subsample\": hp.uniform(\"subsample\", 0.5, 1.0),\n",
    "            \"min_samples_split\": hp.quniform(\"min_samples_split\", 2, 20, 1),\n",
    "            \"min_samples_leaf\": hp.quniform(\"min_samples_leaf\", 1, 10, 1),\n",
    "        },\n",
    "        \"cast\": lambda p: {\n",
    "            **p,\n",
    "            \"n_estimators\": int(p[\"n_estimators\"]),\n",
    "            \"max_depth\": int(p[\"max_depth\"]),\n",
    "            \"min_samples_split\": int(p[\"min_samples_split\"]),\n",
    "            \"min_samples_leaf\": int(p[\"min_samples_leaf\"]),\n",
    "        },\n",
    "    },\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d62d82ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import make_scorer, mean_squared_error\n",
    "import mlflow.sklearn\n",
    "from hyperopt import fmin, tpe, Trials, STATUS_OK\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json, joblib, tempfile\n",
    "\n",
    "SEED = 42\n",
    "CV_FOLDS = 5\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "rmse_scorer = make_scorer(rmse, greater_is_better=False)\n",
    "\n",
    "def make_pipeline(model_key, params, cat_cols, num_cols):\n",
    "    preproc = make_preprocessor(cat_cols, num_cols)\n",
    "    estimator = MODEL_REGISTRY[model_key][\"factory\"](params)\n",
    "    pipe = Pipeline([\n",
    "        (\"preprocessor\", preproc),\n",
    "        (\"model\", estimator),\n",
    "    ])\n",
    "    return pipe\n",
    "\n",
    "def objective(model_key, X, y, cat_cols, num_cols, exp_id=None):\n",
    "    space = MODEL_REGISTRY[model_key][\"space\"]\n",
    "    caster = MODEL_REGISTRY[model_key][\"cast\"]\n",
    "\n",
    "    def _obj(raw_params):\n",
    "        params = caster(dict(raw_params)) if raw_params else {}\n",
    "        with mlflow.start_run(run_name=f\"{model_key}-hyperopt\"):\n",
    "            mlflow.set_tags({\n",
    "                \"model_key\": model_key,\n",
    "                \"stage\": \"hyperopt\",\n",
    "                \"cv_folds\": CV_FOLDS,\n",
    "            })\n",
    "            mlflow.log_params(params)\n",
    "\n",
    "            pipe = make_pipeline(model_key, params, cat_cols, num_cols)\n",
    "            cv = KFold(n_splits=CV_FOLDS, shuffle=True, random_state=SEED)\n",
    "\n",
    "            # cross_val_score returns negative RMSE because greater_is_better=False\n",
    "            scores = cross_val_score(pipe, X, y, scoring=rmse_scorer, cv=cv, n_jobs=-1)\n",
    "            rmse_cv = -scores  # make positive\n",
    "\n",
    "            mlflow.log_metric(\"rmse_mean\", float(rmse_cv.mean()))\n",
    "            mlflow.log_metric(\"rmse_std\", float(rmse_cv.std()))\n",
    "            for i, s in enumerate(rmse_cv, 1):\n",
    "                mlflow.log_metric(f\"rmse_fold_{i}\", float(s))\n",
    "\n",
    "            # Fit once on full training for artifact logging\n",
    "            pipe.fit(X, y)\n",
    "            mlflow.sklearn.log_model(pipe, artifact_path=\"model\")\n",
    "\n",
    "            # Also dump params as artifact for convenience\n",
    "            with tempfile.TemporaryDirectory() as tmp:\n",
    "                with open(os.path.join(tmp, \"params.json\"), \"w\") as f:\n",
    "                    json.dump(params, f, indent=2)\n",
    "                mlflow.log_artifacts(tmp, artifact_path=\"run_meta\")\n",
    "\n",
    "            return {\"loss\": float(rmse_cv.mean()), \"status\": STATUS_OK}\n",
    "\n",
    "    return space, _obj\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a52e7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import Trials\n",
    "\n",
    "def run_search(model_key, X, y, cat_cols, num_cols, max_evals=30, exp_id=None):\n",
    "    entry = MODEL_REGISTRY[model_key]\n",
    "    space = entry[\"space\"]\n",
    "    cast  = entry[\"cast\"]\n",
    "\n",
    "    print(f\"=== Searching {model_key} with {max_evals} evals ===\")\n",
    "\n",
    "    # --- No hyperparameters: do a single CV run + fit, log to MLflow ---\n",
    "    if not space:   # handles {} or None\n",
    "        params = {}\n",
    "        pipe = make_pipeline(model_key, params, cat_cols, num_cols)\n",
    "\n",
    "        from sklearn.model_selection import KFold, cross_val_score\n",
    "        cv = KFold(n_splits=CV_FOLDS, shuffle=True, random_state=SEED)\n",
    "        scores = cross_val_score(pipe, X, y, scoring=rmse_scorer, cv=cv, n_jobs=-1)\n",
    "        rmse_cv = -scores\n",
    "\n",
    "        with mlflow.start_run(experiment_id=exp_id, run_name=f\"{model_key}-no_search\"):\n",
    "            mlflow.set_tags({\"model_key\": model_key, \"stage\": \"hyperopt\", \"cv_folds\": CV_FOLDS})\n",
    "            mlflow.log_metric(\"rmse_mean\", float(rmse_cv.mean()))\n",
    "            mlflow.log_metric(\"rmse_std\",  float(rmse_cv.std()))\n",
    "            for i, s in enumerate(rmse_cv, 1):\n",
    "                mlflow.log_metric(f\"rmse_fold_{i}\", float(s))\n",
    "            pipe.fit(X, y)\n",
    "            mlflow.sklearn.log_model(pipe, artifact_path=\"model\")\n",
    "\n",
    "        return pipe, params, None\n",
    "\n",
    "    # --- Regular Hyperopt path ---\n",
    "    space, obj = objective(model_key, X, y, cat_cols, num_cols, exp_id)\n",
    "\n",
    "    trials = Trials()\n",
    "    best_raw = fmin(fn=obj, space=space, algo=tpe.suggest,\n",
    "                    max_evals=max_evals, trials=trials,\n",
    "                    rstate=np.random.default_rng(SEED))\n",
    "\n",
    "    best_params = cast(dict(best_raw))\n",
    "    best_pipe = make_pipeline(model_key, best_params, cat_cols, num_cols)\n",
    "    best_pipe.fit(X, y)\n",
    "\n",
    "    print(\"Best params:\", best_params)\n",
    "    return best_pipe, best_params, trials\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3d172e35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Searching gbr with 25 evals ===\n",
      "  0%|          | 0/25 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/13 20:31:00 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "\n",
      "2025/10/13 20:31:00 INFO mlflow.tracking._tracking_service.client: ðŸƒ View run gbr-hyperopt at: http://localhost:5001/#/experiments/284535062331422681/runs/0c2ddb36f02640b788950f52d4c9b5a4.\n",
      "\n",
      "2025/10/13 20:31:00 INFO mlflow.tracking._tracking_service.client: ðŸ§ª View experiment at: http://localhost:5001/#/experiments/284535062331422681.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  4%|â–         | 1/25 [10:01<4:00:47, 601.99s/trial, best loss: 0.10045919045891556]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/13 20:35:36 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "\n",
      "2025/10/13 20:35:36 INFO mlflow.tracking._tracking_service.client: ðŸƒ View run gbr-hyperopt at: http://localhost:5001/#/experiments/284535062331422681/runs/46e1e2a0aae8419b93ddd1e1986ac5b7.\n",
      "\n",
      "2025/10/13 20:35:36 INFO mlflow.tracking._tracking_service.client: ðŸ§ª View experiment at: http://localhost:5001/#/experiments/284535062331422681.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  8%|â–Š         | 2/25 [14:37<2:37:10, 410.01s/trial, best loss: 0.10045919045891556]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/13 20:36:42 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "\n",
      "2025/10/13 20:36:43 INFO mlflow.tracking._tracking_service.client: ðŸƒ View run gbr-hyperopt at: http://localhost:5001/#/experiments/284535062331422681/runs/80b87f4d978a45fba5a053a17ef29181.\n",
      "\n",
      "2025/10/13 20:36:43 INFO mlflow.tracking._tracking_service.client: ðŸ§ª View experiment at: http://localhost:5001/#/experiments/284535062331422681.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 12%|â–ˆâ–        | 3/25 [15:44<1:32:49, 253.14s/trial, best loss: 0.0566114062695119] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/13 20:37:35 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "\n",
      "2025/10/13 20:37:35 INFO mlflow.tracking._tracking_service.client: ðŸƒ View run gbr-hyperopt at: http://localhost:5001/#/experiments/284535062331422681/runs/56f40421389b41c78e49c9011fc1e2f9.\n",
      "\n",
      "2025/10/13 20:37:35 INFO mlflow.tracking._tracking_service.client: ðŸ§ª View experiment at: http://localhost:5001/#/experiments/284535062331422681.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 16%|â–ˆâ–Œ        | 4/25 [16:36<1:00:51, 173.89s/trial, best loss: 0.0566114062695119]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/13 20:38:38 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "\n",
      "2025/10/13 20:38:38 INFO mlflow.tracking._tracking_service.client: ðŸƒ View run gbr-hyperopt at: http://localhost:5001/#/experiments/284535062331422681/runs/30940637dacb4345a478122c56002edd.\n",
      "\n",
      "2025/10/13 20:38:38 INFO mlflow.tracking._tracking_service.client: ðŸ§ª View experiment at: http://localhost:5001/#/experiments/284535062331422681.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 20%|â–ˆâ–ˆ        | 5/25 [17:39<44:39, 134.00s/trial, best loss: 0.0566114062695119]  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/13 20:42:03 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "\n",
      "2025/10/13 20:42:03 INFO mlflow.tracking._tracking_service.client: ðŸƒ View run gbr-hyperopt at: http://localhost:5001/#/experiments/284535062331422681/runs/7db9b1790da84142a1a551b1634fb9bd.\n",
      "\n",
      "2025/10/13 20:42:03 INFO mlflow.tracking._tracking_service.client: ðŸ§ª View experiment at: http://localhost:5001/#/experiments/284535062331422681.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 24%|â–ˆâ–ˆâ–       | 6/25 [21:04<50:00, 157.92s/trial, best loss: 0.0566114062695119]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/13 20:48:24 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "\n",
      "2025/10/13 20:48:24 INFO mlflow.tracking._tracking_service.client: ðŸƒ View run gbr-hyperopt at: http://localhost:5001/#/experiments/284535062331422681/runs/0205f839f41f4e42838b7ab35b093785.\n",
      "\n",
      "2025/10/13 20:48:24 INFO mlflow.tracking._tracking_service.client: ðŸ§ª View experiment at: http://localhost:5001/#/experiments/284535062331422681.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 28%|â–ˆâ–ˆâ–Š       | 7/25 [27:25<1:09:19, 231.09s/trial, best loss: 0.056500124139159044]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/13 20:51:10 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "\n",
      "2025/10/13 20:51:10 INFO mlflow.tracking._tracking_service.client: ðŸƒ View run gbr-hyperopt at: http://localhost:5001/#/experiments/284535062331422681/runs/ff908cad263a470f9b0558c7819eab89.\n",
      "\n",
      "2025/10/13 20:51:10 INFO mlflow.tracking._tracking_service.client: ðŸ§ª View experiment at: http://localhost:5001/#/experiments/284535062331422681.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 32%|â–ˆâ–ˆâ–ˆâ–      | 8/25 [30:11<59:32, 210.14s/trial, best loss: 0.056500124139159044]  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/13 21:06:28 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "\n",
      "2025/10/13 21:06:28 INFO mlflow.tracking._tracking_service.client: ðŸƒ View run gbr-hyperopt at: http://localhost:5001/#/experiments/284535062331422681/runs/de68ebdc62e243fca551a701000f5df1.\n",
      "\n",
      "2025/10/13 21:06:28 INFO mlflow.tracking._tracking_service.client: ðŸ§ª View experiment at: http://localhost:5001/#/experiments/284535062331422681.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 9/25 [45:29<1:55:06, 431.63s/trial, best loss: 0.056500124139159044]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/13 21:10:47 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "\n",
      "2025/10/13 21:10:47 INFO mlflow.tracking._tracking_service.client: ðŸƒ View run gbr-hyperopt at: http://localhost:5001/#/experiments/284535062331422681/runs/0c4656cb51be40c3b17be0f89fa83be6.\n",
      "\n",
      "2025/10/13 21:10:47 INFO mlflow.tracking._tracking_service.client: ðŸ§ª View experiment at: http://localhost:5001/#/experiments/284535062331422681.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 10/25 [49:48<1:34:34, 378.31s/trial, best loss: 0.05641483309335117]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/13 21:12:59 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "\n",
      "2025/10/13 21:12:59 INFO mlflow.tracking._tracking_service.client: ðŸƒ View run gbr-hyperopt at: http://localhost:5001/#/experiments/284535062331422681/runs/f6519170815e45519772bc12b555e9a1.\n",
      "\n",
      "2025/10/13 21:12:59 INFO mlflow.tracking._tracking_service.client: ðŸ§ª View experiment at: http://localhost:5001/#/experiments/284535062331422681.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 11/25 [52:00<1:10:38, 302.76s/trial, best loss: 0.05641483309335117]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/13 21:16:21 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "\n",
      "2025/10/13 21:16:21 INFO mlflow.tracking._tracking_service.client: ðŸƒ View run gbr-hyperopt at: http://localhost:5001/#/experiments/284535062331422681/runs/b022dd9645ed47cca4631d0bef24b097.\n",
      "\n",
      "2025/10/13 21:16:21 INFO mlflow.tracking._tracking_service.client: ðŸ§ª View experiment at: http://localhost:5001/#/experiments/284535062331422681.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 12/25 [55:23<59:00, 272.37s/trial, best loss: 0.05641483309335117]  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/13 21:24:20 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "\n",
      "2025/10/13 21:24:20 INFO mlflow.tracking._tracking_service.client: ðŸƒ View run gbr-hyperopt at: http://localhost:5001/#/experiments/284535062331422681/runs/c75001e425934a45b25609241640cd36.\n",
      "\n",
      "2025/10/13 21:24:20 INFO mlflow.tracking._tracking_service.client: ðŸ§ª View experiment at: http://localhost:5001/#/experiments/284535062331422681.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 13/25 [1:03:21<1:06:59, 334.95s/trial, best loss: 0.05638477732136464]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/13 21:30:23 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "\n",
      "2025/10/13 21:30:23 INFO mlflow.tracking._tracking_service.client: ðŸƒ View run gbr-hyperopt at: http://localhost:5001/#/experiments/284535062331422681/runs/ba75af668a334e1dadf25ed256be5911.\n",
      "\n",
      "2025/10/13 21:30:23 INFO mlflow.tracking._tracking_service.client: ðŸ§ª View experiment at: http://localhost:5001/#/experiments/284535062331422681.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 14/25 [1:09:24<1:02:55, 343.19s/trial, best loss: 0.05638477732136464]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/13 21:33:41 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "\n",
      "2025/10/13 21:33:41 INFO mlflow.tracking._tracking_service.client: ðŸƒ View run gbr-hyperopt at: http://localhost:5001/#/experiments/284535062331422681/runs/9d0b9d422c0e43f6ad69f8c0cf555939.\n",
      "\n",
      "2025/10/13 21:33:41 INFO mlflow.tracking._tracking_service.client: ðŸ§ª View experiment at: http://localhost:5001/#/experiments/284535062331422681.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 15/25 [1:12:42<49:55, 299.52s/trial, best loss: 0.05638477732136464]  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/13 21:51:06 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "\n",
      "2025/10/13 21:51:06 INFO mlflow.tracking._tracking_service.client: ðŸƒ View run gbr-hyperopt at: http://localhost:5001/#/experiments/284535062331422681/runs/f03c31ece48d457aa2e616283722e0ca.\n",
      "\n",
      "2025/10/13 21:51:06 INFO mlflow.tracking._tracking_service.client: ðŸ§ª View experiment at: http://localhost:5001/#/experiments/284535062331422681.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 16/25 [1:30:07<1:18:36, 524.02s/trial, best loss: 0.05638477732136464]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/13 21:56:08 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "\n",
      "2025/10/13 21:56:08 INFO mlflow.tracking._tracking_service.client: ðŸƒ View run gbr-hyperopt at: http://localhost:5001/#/experiments/284535062331422681/runs/76e6133d5cb34390bd37a0329e65b30c.\n",
      "\n",
      "2025/10/13 21:56:08 INFO mlflow.tracking._tracking_service.client: ðŸ§ª View experiment at: http://localhost:5001/#/experiments/284535062331422681.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 17/25 [1:35:09<1:00:56, 457.08s/trial, best loss: 0.05638477732136464]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/13 21:56:57 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "\n",
      "2025/10/13 21:56:57 INFO mlflow.tracking._tracking_service.client: ðŸƒ View run gbr-hyperopt at: http://localhost:5001/#/experiments/284535062331422681/runs/9971b805c155446fa076f2a480cdb288.\n",
      "\n",
      "2025/10/13 21:56:57 INFO mlflow.tracking._tracking_service.client: ðŸ§ª View experiment at: http://localhost:5001/#/experiments/284535062331422681.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 18/25 [1:35:58<39:01, 334.48s/trial, best loss: 0.05638477732136464]  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/13 22:01:08 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "\n",
      "2025/10/13 22:01:08 INFO mlflow.tracking._tracking_service.client: ðŸƒ View run gbr-hyperopt at: http://localhost:5001/#/experiments/284535062331422681/runs/7ae03a88b76f4d088d9170edeec8b4c1.\n",
      "\n",
      "2025/10/13 22:01:08 INFO mlflow.tracking._tracking_service.client: ðŸ§ª View experiment at: http://localhost:5001/#/experiments/284535062331422681.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 19/25 [1:40:09<30:56, 309.43s/trial, best loss: 0.05638477732136464]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/13 22:04:56 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "\n",
      "2025/10/13 22:04:56 INFO mlflow.tracking._tracking_service.client: ðŸƒ View run gbr-hyperopt at: http://localhost:5001/#/experiments/284535062331422681/runs/6f70da8eb392434d8007b9c3e900b0fa.\n",
      "\n",
      "2025/10/13 22:04:56 INFO mlflow.tracking._tracking_service.client: ðŸ§ª View experiment at: http://localhost:5001/#/experiments/284535062331422681.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 20/25 [1:43:57<23:44, 284.91s/trial, best loss: 0.05638477732136464]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/13 22:08:25 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "\n",
      "2025/10/13 22:08:25 INFO mlflow.tracking._tracking_service.client: ðŸƒ View run gbr-hyperopt at: http://localhost:5001/#/experiments/284535062331422681/runs/5b28c54c49704f4eb2a3a7419616c9b4.\n",
      "\n",
      "2025/10/13 22:08:25 INFO mlflow.tracking._tracking_service.client: ðŸ§ª View experiment at: http://localhost:5001/#/experiments/284535062331422681.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 21/25 [1:47:26<17:29, 262.29s/trial, best loss: 0.05638477732136464]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/13 22:11:35 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "\n",
      "2025/10/13 22:11:35 INFO mlflow.tracking._tracking_service.client: ðŸƒ View run gbr-hyperopt at: http://localhost:5001/#/experiments/284535062331422681/runs/aacb2e95875245049283a43c1f715425.\n",
      "\n",
      "2025/10/13 22:11:35 INFO mlflow.tracking._tracking_service.client: ðŸ§ª View experiment at: http://localhost:5001/#/experiments/284535062331422681.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 22/25 [1:50:36<12:02, 240.68s/trial, best loss: 0.05638477732136464]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/13 22:15:02 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "\n",
      "2025/10/13 22:15:02 INFO mlflow.tracking._tracking_service.client: ðŸƒ View run gbr-hyperopt at: http://localhost:5001/#/experiments/284535062331422681/runs/64fac3585d0f4faabbfba4bde2b36772.\n",
      "\n",
      "2025/10/13 22:15:02 INFO mlflow.tracking._tracking_service.client: ðŸ§ª View experiment at: http://localhost:5001/#/experiments/284535062331422681.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 23/25 [1:54:03<07:41, 230.52s/trial, best loss: 0.05638477732136464]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/13 23:40:16 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "\n",
      "2025/10/13 23:40:16 INFO mlflow.tracking._tracking_service.client: ðŸƒ View run gbr-hyperopt at: http://localhost:5001/#/experiments/284535062331422681/runs/270c73a306684bdcbe74b3df49ce85b5.\n",
      "\n",
      "2025/10/13 23:40:16 INFO mlflow.tracking._tracking_service.client: ðŸ§ª View experiment at: http://localhost:5001/#/experiments/284535062331422681.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 24/25 [3:19:17<28:15, 1695.73s/trial, best loss: 0.05638477732136464]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/14 00:50:28 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "\n",
      "2025/10/14 00:50:28 INFO mlflow.tracking._tracking_service.client: ðŸƒ View run gbr-hyperopt at: http://localhost:5001/#/experiments/284535062331422681/runs/2b95de56c7054593a6e474b2fd906adf.\n",
      "\n",
      "2025/10/14 00:50:28 INFO mlflow.tracking._tracking_service.client: ðŸ§ª View experiment at: http://localhost:5001/#/experiments/284535062331422681.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [4:29:29<00:00, 646.79s/trial, best loss: 0.05638477732136464] \n",
      "Best params: {'learning_rate': 0.04446902279053312, 'max_depth': 7, 'min_samples_leaf': 3, 'min_samples_split': 13, 'n_estimators': 379, 'subsample': 0.6415804690150524}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/14 01:45:08 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/10/14 01:45:08 INFO mlflow.tracking._tracking_service.client: ðŸƒ View run gbr-final at: http://localhost:5001/#/experiments/284535062331422681/runs/2ca470e9791e4cf1aa907d9c0f04f76d.\n",
      "2025/10/14 01:45:08 INFO mlflow.tracking._tracking_service.client: ðŸ§ª View experiment at: http://localhost:5001/#/experiments/284535062331422681.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>test_rmse</th>\n",
       "      <th>best_params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gbr</td>\n",
       "      <td>0.055806</td>\n",
       "      <td>{'learning_rate': 0.04446902279053312, 'max_de...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model  test_rmse                                        best_params\n",
       "0   gbr   0.055806  {'learning_rate': 0.04446902279053312, 'max_de..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assumes you already did:\n",
    "# train_data, test_data loaded\n",
    "y_train = train_data['accident_risk'].values\n",
    "y_test  = test_data['accident_risk'].values\n",
    "num_features = ['curvature']\n",
    "cat_features = ['speed_limit', 'lighting', 'num_reported_accidents', 'weather']\n",
    "\n",
    "X_train = train_data[cat_features + num_features]\n",
    "X_test  = test_data[cat_features + num_features]\n",
    "\n",
    "results = []\n",
    "\n",
    "#for key, evals in [(\"linreg\", 0), (\"ridge\", 40), (\"lasso\", 40), (\"elasticnet\", 60), (\"rf\", 60), (\"gbr\", 80)]:\n",
    "for key, evals in [(\"gbr\", 25)]:\n",
    "    model, best_params, trials = run_search(key, X_train, y_train, cat_features, num_features, max_evals=evals)\n",
    "    y_pred = model.predict(X_test)\n",
    "    test_rmse = rmse(y_test, y_pred)\n",
    "\n",
    "    # Log a final run per model family for the test result\n",
    "    with mlflow.start_run(run_name=f\"{key}-final\"):\n",
    "        mlflow.set_tags({\"model_key\": key, \"stage\": \"final_test\"})\n",
    "        mlflow.log_params(best_params)\n",
    "        mlflow.log_metric(\"test_rmse\", float(test_rmse))\n",
    "        mlflow.sklearn.log_model(model, artifact_path=\"model\")\n",
    "\n",
    "    results.append({\"model\": key, \"test_rmse\": float(test_rmse), \"best_params\": best_params})\n",
    "\n",
    "pd.DataFrame(results).sort_values(\"test_rmse\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_kaggle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
